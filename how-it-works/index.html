



<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="Genetic programming tool for classification and regression">
      
      
        <link rel="canonical" href="https://maxhalford.github.io/xgp/how-it-works/">
      
      
        <meta name="author" content="Max Halford">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.1, mkdocs-material-3.0.3">
    
    
      
        <title>How it works - XGP</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.451f80e5.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.22915126.css">
      
      
        
        
        <meta name="theme-color" content="#009688">
      
    
    
      <script src="../assets/javascripts/modernizr.1aa3b519.js"></script>
    
    
      <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
      
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="teal" data-md-color-accent="cyan">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="../#how-it-works" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://maxhalford.github.io/xgp" title="XGP" class="md-header-nav__button md-logo">
          
            <i class="md-icon">home</i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                XGP
              </span>
              <span class="md-header-nav__topic">
                How it works
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          
            <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
            
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
          
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  


  <a href="https://github.com/MaxHalford/xgp/" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#__github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      GitHub
    </div>
  </a>

          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://maxhalford.github.io/xgp" title="XGP" class="md-nav__button md-logo">
      
        <i class="md-icon">home</i>
      
    </a>
    XGP
  </label>
  
    <div class="md-nav__source">
      


  


  <a href="https://github.com/MaxHalford/xgp/" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#__github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      GitHub
    </div>
  </a>

    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Introduction" class="md-nav__link">
      Introduction
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        How it works
      </label>
    
    <a href="./" title="How it works" class="md-nav__link md-nav__link--active">
      How it works
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#a-quick-introduction-to-symbolic-regression" title="A quick introduction to symbolic regression" class="md-nav__link">
    A quick introduction to symbolic regression
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#xgp-implementation-details" title="XGP implementation details" class="md-nav__link">
    XGP implementation details
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../cli/" title="CLI usage" class="md-nav__link">
      CLI usage
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../go/" title="Go usage" class="md-nav__link">
      Go usage
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../python/" title="Python usage" class="md-nav__link">
      Python usage
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../training-parameters/" title="Training parameters" class="md-nav__link">
      Training parameters
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#a-quick-introduction-to-symbolic-regression" title="A quick introduction to symbolic regression" class="md-nav__link">
    A quick introduction to symbolic regression
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#xgp-implementation-details" title="XGP implementation details" class="md-nav__link">
    XGP implementation details
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/MaxHalford/xgp/edit/master/docs/how-it-works.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="how-it-works">How it works</h1>
<h2 id="a-quick-introduction-to-symbolic-regression">A quick introduction to symbolic regression</h2>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>If you're looking for an in depth explanation to genetic programming (of which symbolic regression is a subset) check out <a href="http://www.gp-field-guide.org.uk/"><em>A Field Guide to Genetic Programming</em></a>.</p>
</div>
<p>Symbolic regression is a subset of genetic programming. It is a supervised learning method where the structure of the model is not fixed. For example in linear regression the model is constrained to have a certain shape, e.g.</p>
<p>
<script type="math/tex; mode=display">y = w_0x_0 + w_1x_1 + b</script>
</p>
<p>In symbolic regression the model can take many shapes. For example the following equation is valid in symbolic regression.</p>
<p>
<script type="math/tex; mode=display">y = cos(x_0) \times log(sin(x_1)) \times \frac{3.14}{x_0} + 2.17</script>
</p>
<p><em>Anything goes</em>. Symbolic regression is thus a very flexible approach. The idea is to run an optimisation procedure to look for the best structure <em>and</em> the best parameters. The obvious downside is that the search space becomes huge and unexplorable by standard gradient-based methods.</p>
<p>A symbolic regression model is composed of three different kinds of so-called <strong>operators</strong>:</p>
<ul>
<li><strong>Functions</strong> which are basic mathematical functions such as \(cos\) and \(log\),</li>
<li><strong>Constants</strong> which are simply floating point values such as 3.14 and 2.17,</li>
<li><strong>Variables</strong> which are features in a dataset such as \(x_0\) and \(x_1\).</li>
</ul>
<p>Each operator, regardless of it's type, has an <strong>arity</strong> which determines how many operands it takes. For example the multiplication operator has an arity of 2. All functions have an arity of 1 or more, whilst constants and variables have an arity of 0. Arity is needed internally to determine if an equation is legal or not. For example a function with an arity of 2 should have two operands. The idea is that an equation can be represented as a tree with each node being an operator and each branch an operand. For example the following tree represents the equation presented above.</p>
<p><img alt="example1" src="../img/example1.png" /></p>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>This diagram was generated with the <a href="cli#visualization">CLI's todot command</a>.</p>
</div>
<p>The goal of symbolic regression is to find an optimal combination of operators. Not only do appropriate operators have to be chosen, they also have to associated in a good way. The search space is very complex and cannot be explored with gradient-based optimization techniques. Instead symbolic regression relies on <strong>evolutionary algorithms</strong> such as <strong>genetic algorithms</strong> (which is what XGP uses) to perform the optimization. Under the hood XGP uses <a href="https://github.com/MaxHalford/eaopt">eaopt</a>.</p>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>Symbolic regression is part of the larger family of <strong>genetic programming</strong>.</p>
</div>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>Although they are very close and related, genetic programming and genetic algorithms are different things.</p>
</div>
<p>In genetic programming combinations of operators are usually referred to as <strong>programs</strong>. Like other genetic programming methods, the idea with symbolic regression is to <strong>evolve</strong> said programs, hopefully by making them at solving the machine learning task as hand.</p>
<p>The first element needed to perform evolutionary optimization is to define the <strong>fitness</strong> of our programs. In a supervised learning setting this is rather easy; indeed we simply have to "run" a program, get it's output, and compute a so-called <strong>loss metric</strong> by comparing the output to the ground truth. The nice thing is that we can use any loss metric, indeed it doesn't have to be differentiable (which is a requirement of gradient-based optimization).</p>
<p>Once we can evaluate the fitness of a program, we can create a set of random programs and sort them according to their fitness. There are different ways to produce random programs. On the one hand we can generate program trees that have a fixed height; this is called <strong>full initialization</strong>. On the other hand we can generate trees that have variable branch heights; this is called as <strong>grow initialization</strong>. A popular method is to use both methods randomly, which is referred to as <strong>ramped half-and-half initialization</strong>.</p>
<p>Given a set of programs and associated fitnesses, we can generate new programs by combining the ones in the current population. This is called <strong>crossover</strong> and is one of the basic patterns of evolution. The idea is to repeatidly sample two parents from the initial population and produce one (or two, it depends) new programs so as to obtain a new population. Normally, if the sampling is weighted by the fitness of each program, the new population will have a higher average fitness. There are different ways to crossover programs. The most basic one (and the only one implemented in XGP for now) is called <strong>subtree crossover</strong>, it consists in picking random nodes from two programs and swapping them.</p>
<p>New programs can also be generated by sampling individual programs and modifying them. This is called <strong>mutation</strong>. Again, there are different kinds of mutation, of which three are implement in XGP. First of all <strong>point mutation</strong> can be used to modify each operator one-by-one. For example point mutation can be used for tuning the constants. Secondly, <strong>hoist mutation</strong> consists in replacing a branch by one of it's leaves. Finally <strong>subtree mutation</strong> picks a random node in a tree and replaces with a randomly generated tree.</p>
<p>Once a new population has been generated, we can evaluate it and repeat the evolution process. At each so-called <strong>generation</strong> we record the best program and put it aside. Once the process has stopped, either because a set number of generations has occurred or because a desired performance has been reached then the best ever program can be used as the final model.</p>
<p>Of course there is a huge element of randomness to symbolic regression. Whats more there are many choices that have to be made. What operators should one pick? How about what evolution strategy to use? The goal of XGP is to provide a solid framework to work with symbolic regression by providing both an efficient implementation and a high-level API.</p>
<h2 id="xgp-implementation-details">XGP implementation details</h2>
<p>The <a href="https://github.com/MaxHalford/xgp">core of XGP</a> is implemented in Go. Go is a good fit for genetic programming because it's concurrency features play nicely with <a href="https://www.wikiwand.com/en/Embarrassingly_parallel">embarrassingly parallel</a> situations such as genetic algorithms. Moreover because the running time of symbolic regression grows exponentially with the number of programs, having a compiled implementation saves a lot of time.</p>
<p>XGP's core code is organized in subpackages. The <a href="https://github.com/MaxHalford/xgp/tree/master/op"><code>op</code> package</a> contains all the available operators and the tree structure necessary for building programs. Each operator satisfies the following interface:</p>
<div class="codehilite"><pre><span></span><span class="kd">type</span> <span class="nx">Operator</span> <span class="kd">interface</span> <span class="p">{</span>
    <span class="nx">Eval</span><span class="p">(</span><span class="nx">X</span> <span class="p">[][]</span><span class="kt">float64</span><span class="p">)</span> <span class="p">[]</span><span class="kt">float64</span>
    <span class="nx">Arity</span><span class="p">()</span> <span class="kt">uint</span>
    <span class="nx">Operand</span><span class="p">(</span><span class="nx">i</span> <span class="kt">uint</span><span class="p">)</span> <span class="nx">Operator</span>
    <span class="nx">SetOperand</span><span class="p">(</span><span class="nx">i</span> <span class="kt">uint</span><span class="p">,</span> <span class="nx">op</span> <span class="nx">Operator</span><span class="p">)</span> <span class="nx">Operator</span>
    <span class="nx">Simplify</span><span class="p">()</span> <span class="nx">Operator</span>
    <span class="nx">Diff</span><span class="p">(</span><span class="nx">i</span> <span class="kt">uint</span><span class="p">)</span> <span class="nx">Operator</span>
    <span class="nx">Name</span><span class="p">()</span> <span class="kt">string</span>
    <span class="nx">String</span><span class="p">()</span> <span class="kt">string</span>
<span class="p">}</span>
</pre></div>


<p>An <code>Operator</code> can "evaluate" a matrix and produce a output. The matrix is a set of features oriented column-wise (some would say Fortran style) to optimize the huge amount of columnar operations symbolic regression has to perform. An <code>Operator</code> also has an arity and a name. An <code>Operator</code> has as many child <code>Operator</code>s as it's arity. An <code>Operator</code> can also be simplified and differentiated. At first the <code>Operator</code> interface seems to require a hefty amount of methods, but in practice it only takes around 100 lines of code to implement.</p>
<p>At a higher-level, a <code>Program</code> is what is used to do the actual learning; it has the following signature:</p>
<div class="codehilite"><pre><span></span><span class="kd">type</span> <span class="nx">Program</span> <span class="kd">struct</span> <span class="p">{</span>
    <span class="nx">Tree</span>      <span class="nx">tree</span><span class="p">.</span><span class="nx">Tree</span>
    <span class="nx">GP</span> <span class="o">*</span><span class="nx">GP</span>
<span class="p">}</span>
</pre></div>


<p>The <code>GP</code> gives the <code>Program</code> context about what it is it has to learn. The <code>GP</code> contains a <code>LossMetric</code> field with determines how to score each <code>Program</code> and if the task is classification or regression. The <code>GP</code> is also the global structure that organizes the programs and handles the learning process. If you want to use XGP with Go then you'll be working with the <code>GP</code> struct. However you shouldn't directly instantiate an <code>GP</code>; instead you should use the <code>GPConfig</code> struct where you can speficify training parameters before calling the <code>NewGP</code> method.</p>
<p>The <a href="https://github.com/MaxHalford/xgp/tree/master/metrics"><code>metrics</code> package</a> is a completely independent package that contains implementations of machine learning metrics (such as accuracy and logarithmic loss). In theory it could be traded for another package if a Go standard appears.</p>
<p>The <a href="https://github.com/MaxHalford/xgp/tree/master/meta"><code>meta</code> package</a> can be used to implement meta-learning algorithms such as <a href="https://www.wikiwand.com/en/Gradient_boosting">gradient boosting</a>. This is predominantly what makes XGP competitive.</p>
<p>XGP has a few tricks up its sleeves (and more are coming):</p>
<ul>
<li>Tree simplication: because programs are randomly modified it can occur that some parts of the program can be simplified. For example the formula <code>add(mul(2, 3), 4)</code> can simply be replaced by <code>10</code>. In practice catching these simplifications and avoiding unnecessary computations helps a lot.</li>
<li>Bloat control: <a href="http://dces.essex.ac.uk/staff/poli/gp-field-guide/113Bloat.html">bloat</a> is an unavoidable problem in genetic program. As the generations go on the programs will have a tendency to grow in complexity. First of all this increases the running time. It also produces complex programs that tend to overfit. By default XGP uses a <strong>parsimony coefficient</strong> to penalize programs based on the number of operators they possess. Controlling bloat can be seen as a form of <a href="https://www.wikiwand.com/en/Regularization_(mathematics)">regularization</a>.</li>
<li>Constant optimisation: the constants of the best program are "polished" using <a href="https://www.wikiwand.com/en/CMA-ES">CMA-ES</a>. This usually takes a negligible amount of time and helps a lot in practice.</li>
<li>Line search: the step size used in gradient boosting is tuned via <a href="https://www.wikiwand.com/en/Line_search">line search</a>.</li>
</ul>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer" style="margin-top: 30px;">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="" title="Introduction" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Introduction
              </span>
            </div>
          </a>
        
        
          <a href="cli/" title="CLI usage" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                CLI usage
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2018 Max Halford
          </div>
        
        powered by
        <a href="http://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
        
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.583bbe55.js"></script>
      
      <script>app.initialize({version:"1.0.1",url:{base:".."}})</script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
    
    
      
    
  </body>
</html>